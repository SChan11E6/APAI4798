{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "mat = scipy.io.loadmat('data_EEG_AI.mat')\n",
    "alphabets = list(map(chr, range(65, 91)))\n",
    "alabel = mat[\"label\"][:,0]\n",
    "label_dict = {}\n",
    "for i in range(len(alabel)):\n",
    "\tif alabel[i] not in label_dict:\n",
    "\t\tlabel_dict[alabel[i]] = [i,7800]\n",
    "\telse:\n",
    "\t\tlabel_dict[alabel[i]][1] = i\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amat = pd.Series(mat)\n",
    "amat = amat[['channel_labels', 'data', 'label', 'time_points']]\n",
    "print(amat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "colname = ['sample_no','channel_labels','label','time_points','data']\n",
    "for i in range(7800*24):\n",
    "\trow_content = []\n",
    "\trow_content.append(i//24)\n",
    "\trow_content.append(mat[\"channel_labels\"][i%24][0][0])\n",
    "\trow_content.append(i//(300*24))\n",
    "\trow_content.append(list(range(-200,3001,4)))\n",
    "\trow_content.append(mat['data'][i%24][:,i//24])\n",
    "\tdf.append(row_content)\n",
    "\t\t\t\n",
    "df = pd.DataFrame(df,columns=colname)\n",
    "#df.to_csv(\"EEG_sorted.csv\",index=False) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(1):\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample = {sample}, label = {alphabets[mat['label'][sample][0]-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\tall.append(mat['data'][channel][time][sample])\n",
    "\t\tplt.plot(mat['time_points'][:,0],all, label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "# overall\n",
    "overall_avg = []\n",
    "for channel in range(len(mat['data'])):\n",
    "    all = []\n",
    "    for time in mat['data'][channel]:\n",
    "        all.append(sum(time)/len(time))\n",
    "    overall_avg.append(all)\n",
    "\n",
    "#each alphabet avg\n",
    "alpha_avg = []\n",
    "for i in label_dict:\n",
    "    avg = []\n",
    "    for channel in range(len(mat['data'])):\n",
    "        all = []\n",
    "        for time in mat['data'][channel]:\n",
    "            all.append(sum(time[label_dict[i][0]:label_dict[i][1]])/300)\n",
    "        avg.append(all)\n",
    "    alpha_avg.append(avg)\n",
    "\n",
    "print(np.array(overall_avg).shape)\n",
    "print(np.array(alpha_avg).shape)\n",
    "\n",
    "alpha_avg_mse = []\n",
    "for i in alpha_avg:\n",
    "    alpha_avg_mse.append(mean_squared_error(overall_avg, i))\n",
    "print(alpha_avg_mse)\n",
    "\n",
    "#heatmap\n",
    "inter_alpha = []\n",
    "for i in alpha_avg:\n",
    "    row = []\n",
    "    for j in alpha_avg:\n",
    "        row.append(mean_squared_error(i, j))\n",
    "    inter_alpha.append(row)\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(np.array(inter_alpha), xticklabels=alphabets, yticklabels=alphabets)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "a = []\n",
    "for i in mat['channel_labels']:\n",
    "    a.append(i[0][0])\n",
    "\n",
    "# overall\n",
    "overall_avg = []\n",
    "for channel in range(len(mat['data'])):\n",
    "    all = []\n",
    "    for time in mat['data'][channel]:\n",
    "        all.append(sum(time)/len(time))\n",
    "    overall_avg.append(all)\n",
    "overall_channel_avg = np.mean(np.array(overall_avg), axis= 0)\n",
    "    \n",
    "\n",
    "#each channel avg\n",
    "channel_avg = []\n",
    "for channel in range(len(mat['data'])):\n",
    "    all = []\n",
    "    for time in mat['data'][channel]:\n",
    "        all.append(sum(time)/len(time))\n",
    "    channel_avg.append(all)\n",
    "\n",
    "print(np.array(overall_channel_avg).shape)\n",
    "print(np.array(channel_avg).shape)\n",
    "\n",
    "channel_avg_mse = []\n",
    "for i in channel_avg:\n",
    "    channel_avg_mse.append(mean_squared_error(overall_channel_avg, i))\n",
    "print(channel_avg_mse)\n",
    "\n",
    "#heatmap\n",
    "inter_channel = []\n",
    "for i in channel_avg:\n",
    "    row = []\n",
    "    for j in channel_avg:\n",
    "        row.append(mean_squared_error(i, j))\n",
    "    inter_channel.append(row)\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(np.array(inter_channel), xticklabels=a, yticklabels=a, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_min = []\n",
    "for channel in range(len(mat['data'])):\n",
    "\tchannel_min = []\n",
    "\tfor time in mat['data'][channel]:\n",
    "\t\tchannel_min.append(min(time))\n",
    "\tall_min.append(channel_min)\n",
    "print(all_min)\n",
    "plt.figure(figsize=(16,9))\n",
    "for c in range(24):\n",
    "\tplt.plot(mat['time_points'][:,0], all_min[c], label=mat['channel_labels'][channel][0][0])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg = []\n",
    "for channel in range(len(mat['data'])):\n",
    "\tchannel_avg = []\n",
    "\tfor time in mat['data'][channel]:\n",
    "\t\tchannel_avg.append(sum(time)/7800)\n",
    "\tall_avg.append(channel_avg)\n",
    "print(all_avg)\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "for c in range(24):\n",
    "\tplt.plot(mat['time_points'][:,0], all_avg[c], label=mat['channel_labels'][c][0][0])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alphabet avg\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in mat['data'][channel]:\n",
    "\t\t\tall.append(sum(time[label_dict[i][0]:label_dict[i][1]])/300)\n",
    "\t\tplt.plot(mat['time_points'][:,0],all, label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alpahbet avg - min for each time frame\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\tall.append(sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300-all_min[channel][time])\n",
    "\t\tplt.plot(mat['time_points'][:,0],all, label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alpahbet avg - total avg for each time frame\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\tall.append(sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300-all_avg[channel][time])\n",
    "\t\tplt.plot(mat['time_points'][:,0],all, label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alphabet avg with sigmoid\n",
    "def sig(x):\n",
    "\treturn 1/(1 + np.exp(-x))\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\tall.append(sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300)\n",
    "\t\tplt.plot(mat['time_points'][:,0], list(map(sig, all)), label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "\treturn 1/(1 + np.exp(-x))\n",
    "for sample in [5,301,601]:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample{sample}\")\n",
    "\tbw = []\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in mat['data'][channel]:\n",
    "\t\t\tall.append(time[sample])\n",
    "\t\tbw.append(list(map(sig, all)))\n",
    "\tim = Image.fromarray(np.array(bw), mode='L')\n",
    "\timshow(np.asarray(im))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alphabet avg with min max normalization\n",
    "\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\ttmp = sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300\n",
    "\t\t\t#norm = np.linalg.norm(tmp)\n",
    "\t\t\t#normalized_array = tmp/norm \n",
    "\t\t\t#all.append(normalized_array)\n",
    "\t\t\tall.append(tmp)\n",
    "\t\tall = np.array(all)\n",
    "\t\tplt.plot(mat['time_points'][:,0], (all-all.min())/(all.max()-all.min()), label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alphabet avg with pandas normalization\n",
    "\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\ttmp = sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300\n",
    "\t\t\t#norm = np.linalg.norm(tmp)\n",
    "\t\t\t#normalized_array = tmp/norm \n",
    "\t\t\t#all.append(normalized_array)\n",
    "\t\t\tall.append(tmp)\n",
    "\t\tall = np.array(all)\n",
    "\t\tplt.plot(mat['time_points'][:,0], (all - all.mean()) / all.std(), label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each alpahbet avg - total avg for each time frame\n",
    "for i in label_dict:\n",
    "\tplt.figure(figsize=(16,9))\n",
    "\tplt.title(f\"sample {label_dict[i][0]} to {label_dict[i][1]} average, label = {alphabets[i-1]}\")\n",
    "\tplt.ylabel(\"potential\")\n",
    "\tplt.xlabel(\"time after stimulus\")\n",
    "\tfor channel in range(len(mat['data'])):\n",
    "\t\tall = []\n",
    "\t\tfor time in range(len(mat['data'][channel])):\n",
    "\t\t\tall.append(sum(mat['data'][channel][time][label_dict[i][0]:label_dict[i][1]])/300-all_avg[channel][time])\n",
    "\t\tall = np.array(all)\n",
    "\t\tplt.plot(mat['time_points'][:,0],(all - all.mean()) / all.std(), label=mat['channel_labels'][channel][0][0])\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW\n",
    "all_dict = {}\n",
    "#each alphabet avg\n",
    "for i in label_dict:\n",
    "    all_dict[alphabets[i-1]] = {}\n",
    "    for channel in range(len(mat['data'])):\n",
    "        all = []\n",
    "        for time in mat['data'][channel]:\n",
    "            all.append(sum(time[label_dict[i][0]:label_dict[i][1]])/300)\n",
    "        all_dict[alphabets[i-1]][mat['channel_labels'][channel][0][0]] = all\n",
    "df = pd.DataFrame.from_dict(all_dict)\n",
    "        \n",
    "#print graph\n",
    "for alpha in ['A','B']:\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.title(f\"label = {alpha}\")\n",
    "    plt.ylabel(\"potential\")\n",
    "    plt.xlabel(\"time after stimulus\")\n",
    "    for channel in df[alpha].keys():\n",
    "        plt.plot(mat['time_points'][:,0],df[alpha][channel], label=channel)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "#print difference graph for P7\n",
    "base_alpha = 'A'\n",
    "base_ch = 'P7'\n",
    "baseline = np.array(df[base_alpha][base_ch])\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(f\"alpha - {base_alpha}, channel = {base_ch}\")\n",
    "plt.ylabel(\"potential\")\n",
    "plt.xlabel(\"time after stimulus\")\n",
    "for alpha in df.keys():\n",
    "    if alpha != base_alpha:\n",
    "        plt.plot(mat['time_points'][:,0],np.array(df[alpha][base_ch])-baseline, label=alpha)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#print difference graph for A and B\n",
    "base_alpha = 'B'\n",
    "alpha = 'A'\n",
    "baseline = df[base_alpha]\n",
    "compare = df[alpha]\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(f\"label = {alpha} - {base_alpha}\")\n",
    "plt.ylabel(\"potential\")\n",
    "plt.xlabel(\"time after stimulus\")\n",
    "for ch in df[base_alpha].keys():\n",
    "    plt.plot(mat['time_points'][:,0],np.array(compare[ch])-baseline[ch], label=ch)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
