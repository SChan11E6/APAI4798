{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVd_l0p2ob4y",
        "outputId": "8e4bcf63-0683-4007-b964-5c04e37263e1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Conv2DTranspose\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mat = scipy.io.loadmat('/content/drive/My Drive/FYP/data_EEG_AI.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LiC8SrwUob43",
        "outputId": "9d267e85-606e-4b8f-863f-0f4b39f360b4"
      },
      "outputs": [],
      "source": [
        "df = []\n",
        "colname = ['sample_no','channel_labels','label','time_points','data']\n",
        "for i in range(7800*24):\n",
        "\trow_content = []\n",
        "\trow_content.append(i//24)\n",
        "\trow_content.append(mat[\"channel_labels\"][i%24][0][0])\n",
        "\trow_content.append(i//(300*24))\n",
        "\trow_content.append(list(range(-200,3001,4)))\n",
        "\trow_content.append(mat['data'][i%24][:,i//24])\n",
        "\tdf.append(row_content)\n",
        "\n",
        "df = pd.DataFrame(df,columns=colname)\n",
        "#df.to_csv(\"EEG_sorted.csv\",index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SPy9rjbob44",
        "outputId": "28e35b8e-4e0d-47bb-d8db-3358e6f4867d"
      },
      "outputs": [],
      "source": [
        "#source: https://www.mdpi.com/1424-8220/22/5/1750\n",
        "ROWS = 24\n",
        "COLS = 801\n",
        "CHANNELS = 1\n",
        "CLASSES = 26\n",
        "\n",
        "def gen_block(X, param1, param2, param3):\n",
        "    _, h, w, ch = X.shape\n",
        "    #param = [filter_size[3,10], stride [3,5], filter number]\n",
        "    X_shortcut = X\n",
        "\n",
        "    # Left Path\n",
        "    X = Conv2D(filters = param1[2], kernel_size = param1[0], strides = param1[1], kernel_initializer = glorot_uniform(seed=0), padding='same')(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters = param2[2], kernel_size = param2[0], strides = param2[1], kernel_initializer = glorot_uniform(seed=0), padding='same')(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    # Right Path\n",
        "    X_shortcut = Conv2D(filters = param3[2], kernel_size = param3[0], strides = param3[1], kernel_initializer = glorot_uniform(seed=0), padding='same')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def Generator(input_shape = (64, 64, 3), classes = 2):\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    param1 = [(3,10), (2,3), 16]\n",
        "    param2 = [(1,1), (1,1), 32]\n",
        "    param3 = [(1,1), (2,3), 32]\n",
        "    X = gen_block(X_input, param1, param2, param3)\n",
        "    param1 = [(3,10), (3,3), 32]\n",
        "    param2 = [(1,1), (1,1), 64]\n",
        "    param3 = [(1,1), (3,3), 64]\n",
        "    X = gen_block(X, param1, param2, param3)\n",
        "    param1 = [(2,3), (2,1), 64]\n",
        "    param2 = [(1,1), (1,1), 128]\n",
        "    param3 = [(1,1), (2,1), 128]\n",
        "    X = gen_block(X, param1, param2, param3)\n",
        "    h, w, ch = input_shape\n",
        "    #X = ZeroPadding2D(((math.floor(h/2), math.ceil(h/2)), (math.floor((w+1)/2), math.ceil((w+1)/2))))(X)\n",
        "    X = Conv2DTranspose(128, kernel_size=(2,3), strides=(2,1), padding = 'same')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    #X = ZeroPadding2D(((h, h), (math.floor((w+3)/2), math.ceil((w+3)/2))))(X)\n",
        "    X = Conv2DTranspose(64, kernel_size=(3,5), strides=(3,3), padding = 'same')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    #X = ZeroPadding2D(((h, h), (math.floor((4*w+5)/2), math.ceil((4*w+5)/2))))(X)\n",
        "    X = Conv2DTranspose(1, kernel_size=(3,10), strides=(2,3), padding = 'same')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='Generator')\n",
        "\n",
        "    return model\n",
        "\n",
        "def disc_block(X, param1, param2, param3):\n",
        "    _, h, w, ch = X.shape\n",
        "    #param = [filter_size[3,10], stride [3,5], filter number]\n",
        "    X_shortcut = X\n",
        "\n",
        "    # Left Path\n",
        "    X = ZeroPadding2D(((math.floor(((param1[1][0]-1)*h+param1[0][0]-param1[1][0])/2), math.ceil(((param1[1][0]-1)*h+param1[0][0]-param1[1][0])/2)), (math.floor(((param1[1][1]-1)*w+param1[0][1]-param1[1][1])/2), math.ceil(((param1[1][1]-1)*w+param1[0][1]-param1[1][1])/2))))(X)\n",
        "    X = Conv2D(filters = param1[2], kernel_size = param1[0], strides = param1[1], kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('leaky_relu')(X)\n",
        "    X = ZeroPadding2D(((math.floor(((param2[1][0]-1)*h+param2[0][0]-param2[1][0])/2), math.ceil(((param2[1][0]-1)*h+param2[0][0]-param2[1][0])/2)), (math.floor(((param2[1][1]-1)*w+param2[0][1]-param2[1][1])/2), math.ceil(((param2[1][1]-1)*w+param2[0][1]-param2[1][1])/2))))(X)\n",
        "    X = Conv2D(filters = param2[2], kernel_size = param2[0], strides = param2[1], kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    # Right Path\n",
        "    X_shortcut = ZeroPadding2D(((math.floor(((param3[1][0]-1)*h+param3[0][0]-param3[1][0])/2), math.ceil(((param3[1][0]-1)*h+param3[0][0]-param3[1][0])/2)), (math.floor(((param3[1][1]-1)*w+param3[0][1]-param3[1][1])/2), math.ceil(((param3[1][1]-1)*w+param3[0][1]-param3[1][1])/2))))(X_shortcut)\n",
        "    X_shortcut = Conv2D(filters = param3[2], kernel_size = param3[0], strides = param3[1], kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('leaky_relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def Discriminator(input_shape = (24, 801, 1), classes = 26):\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    param1 = [(2,10), (2,4), 16]\n",
        "    param2 = [(1,1), (1,1), 32]\n",
        "    param3 = [(1,1), (2,4), 32]\n",
        "    X = disc_block(X_input, param1, param2, param3)\n",
        "    param1 = [(2,5), (2,2), 32]\n",
        "    param2 = [(1,1), (1,1), 64]\n",
        "    param3 = [(1,1), (2,2), 64]\n",
        "    X = disc_block(X, param1, param2, param3)\n",
        "    param1 = [(2,3), (2,2), 64]\n",
        "    param2 = [(1,1), (1,1), 128]\n",
        "    param3 = [(1,1), (2,2), 128]\n",
        "    X = disc_block(X, param1, param2, param3)\n",
        "    param1 = [(2,3), (2,2), 128]\n",
        "    param2 = [(1,1), (1,1), 256]\n",
        "    param3 = [(1,1), (2,2), 256]\n",
        "    X = disc_block(X, param1, param2, param3)\n",
        "    h, w, ch = input_shape\n",
        "    #X = ZeroPadding2D(((math.floor(h/2), math.ceil(h/2)), (math.floor(w/2), math.ceil(w/2))))(X)\n",
        "    X = Conv2D(512, kernel_size=(2,2), strides=(2,2))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('leaky_relu')(X)\n",
        "    #X = ZeroPadding2D(((0, 0), (1, 2)))(X)\n",
        "    X = Conv2D(1, kernel_size=(1,4))(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='Discriminator')\n",
        "\n",
        "    return model\n",
        "\n",
        "gen = Generator(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
        "dis = Discriminator(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
        "\n",
        "gen.summary()\n",
        "dis.summary()\n",
        "\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "checkpoint_dir = '/content/drive/My Drive/FYP/GAN_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=gen,\n",
        "                                 discriminator=dis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G096O0u3ob45",
        "outputId": "24702fa9-79b5-4a8d-aa17-8ed602d84674"
      },
      "outputs": [],
      "source": [
        "# source: https://www.tensorflow.org/tutorials/generative/dcgan\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8\n",
        "noise_dim = (24, 801)\n",
        "num_examples_to_generate = 8\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim[0]*noise_dim[1]], mean=0.0, stddev=1.0)\n",
        "    noise = tf.reshape(noise, [BATCH_SIZE, 24, 801, 1])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = gen(noise, training=True)\n",
        "\n",
        "      real_output = dis(images, training=True)\n",
        "      fake_output = dis(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "      print(f\"gen_loss: {gen_loss}; disc_loss = {disc_loss}\\n\")\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, dis.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  dataset = tf.split(dataset, num_or_size_splits = math.ceil(dataset.shape[0]/BATCH_SIZE))\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "data = np.reshape(np.vstack(df['data'].to_numpy()), (7800, 24, 801))\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, np.array([i//(300) for i in range(7800)]), test_size=0.2, random_state=0)\n",
        "train(x_train, EPOCHS)\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INSGIJyTjSZA",
        "outputId": "022fd84e-daaa-4845-c118-0d9ff1a93045"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OSjjoZsSyFUM",
        "outputId": "b2317fba-ece8-4f88-b39c-52faa58de919"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  out = gen(np.reshape(data[i], (1, 24, 801, 1)))\n",
        "  out = np.reshape(out, (24,801))\n",
        "  plt.figure(figsize=(16,9))\n",
        "  plt.ylabel(\"potential\")\n",
        "  plt.xlabel(\"time after stimulus\")\n",
        "  for channel in range(len(out)):\n",
        "    plt.plot(mat['time_points'][:,0],out[channel], label=mat['channel_labels'][channel][0][0])\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "dusyv8xx05lQ",
        "outputId": "feb119e9-bd0d-4ac1-bb6e-ae64aaf0d8ba"
      },
      "outputs": [],
      "source": [
        "di = {}\n",
        "for i in range(len(data)):\n",
        "  out_2d = np.reshape(gen(np.reshape(data[i], (1, 24, 801, 1))), (24,801))\n",
        "  for j in range(24):\n",
        "    di[i*24+j] = out_2d[j]\n",
        "output_df = pd.DataFrame.from_dict(di, orient='index')\n",
        "print(len(output_df))\n",
        "output_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ses1Qfeb4rfx"
      },
      "outputs": [],
      "source": [
        "output_df.to_csv('/content/drive/My Drive/FYP/out.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
